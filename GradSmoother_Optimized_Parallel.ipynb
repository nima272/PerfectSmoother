{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6768b2f-301d-4180-98db-54bdfc413a19",
   "metadata": {},
   "source": [
    "# Main code to run with mpi for cross validation standard error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b5ea4d-c4bc-4a67-aeee-d87446bd0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mpi_GraduationSmoother.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sksparse.cholmod import cholesky\n",
    "import plotly.graph_objects as go\n",
    "from scipy.sparse import diags, csr_matrix, csc_matrix\n",
    "from scipy.sparse.linalg import inv\n",
    "import math\n",
    "from scipy.linalg import solve_triangular\n",
    "from scipy.sparse.linalg import inv\n",
    "\n",
    "# Inputs\n",
    "\"\"\"\n",
    "\"Graduation\" smoothing technique based on the methodology proposed by: \n",
    "    Eilers, P.H., 2003. A perfect smoother. Analytical chemistry, 75(14), pp.3631-3636. \n",
    "after \n",
    "    Whittaker, E.T., 1922. On a new method of graduation. Proceedings of the Edinburgh Mathematical Society, 41, pp.63-75.\n",
    "\n",
    "\n",
    "The code also includes finding the optimal value for coefficient 'lambda', in parallel. \n",
    "\n",
    "\n",
    "INPUTS:\n",
    "    INPUT_xy.csv:     is the input data file for smoothing purpose. \n",
    "                      It has two columns with headers, x and y. \n",
    "                      First column is the x (can be non-uniformly sampled). \n",
    "                      The second column is the y (to be smoothed).\n",
    "                      The file is in the same folder as the main code.\n",
    "    \n",
    "    diff_order:       differentiation order.\n",
    "    lambdas:          range of the lambdas over which the cross validation standard error is calculated.\n",
    "\n",
    "\n",
    "OUTPUTS:\n",
    "    mpi_results.txt:  the cross validation standar error for every lamdas set as input\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "diff_order = 2\n",
    "lambdas = np.logspace(1, 6, 24)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_CVSE_for_lambda(lambda_, diff_order, w, y):\n",
    "    \"\"\"\n",
    "    Calculate the cross validation standard error of smoothed data for a given lambda_.\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    for i in range(m - diff_order):\n",
    "        for j in range(diff_order + 1):\n",
    "            rows.append(i)\n",
    "            cols.append(i + j)\n",
    "            data.append((-1)**(diff_order - j) * math.comb(diff_order, j))\n",
    "\n",
    "    D = csc_matrix((data, (rows, cols)), shape=(m - diff_order, m))\n",
    "    W = diags(w, 0, format='csc')\n",
    "    A = (W + lambda_ * (D.T @ D))\n",
    "    wy = w * y\n",
    "    factor = cholesky(A)\n",
    "    z = factor(wy)\n",
    "       \n",
    "    Ainv=inv(A)\n",
    "    Ainv_W=Ainv.dot(W)\n",
    "    Ainv_W_Arr=Ainv_W.toarray()\n",
    "    Ainv_W_Arr_Diag=Ainv_W_Arr.diagonal()\n",
    "    \n",
    "    CV_SE = 0\n",
    "    non_zero_no = 0\n",
    "\n",
    "    for ii in range(0, len(y)):\n",
    "        if y[ii] != 0:\n",
    "            non_zero_no += 1\n",
    "            CV_SE += ((y[ii] - z[ii]) / (1 - Ainv_W_Arr_Diag[ii]))**2\n",
    "    CV_SE = np.sqrt((CV_SE / non_zero_no))\n",
    "\n",
    "    return lambda_, CV_SE\n",
    "\n",
    "data = pd.read_csv('INPUT_xy.csv')\n",
    "\n",
    "data.set_index('X', inplace=True)\n",
    "data.index = (data.index - data.index[0])\n",
    "max_X = data.index.max()\n",
    "new_index = pd.RangeIndex(start=data.index[0], stop=int(max_X) + 1, step=1)\n",
    "new_data = pd.DataFrame(index=new_index, columns=['y'])\n",
    "new_data['y'] = 0.0\n",
    "new_data.index.name='X'\n",
    "for X in new_data.index:\n",
    "    if X in data.index:\n",
    "        new_data.at[X, 'y'] = data.loc[data.index == X, 'y'].values[0]\n",
    "new_data['weights'] = 0.0\n",
    "for X in new_data.index:\n",
    "    if new_data.at[X, 'y']!=0:\n",
    "        new_data.at[X, 'weights'] = 1\n",
    "        \n",
    "w = new_data['weights'].to_numpy()\n",
    "y = new_data['y'].to_numpy()\n",
    "\n",
    "\n",
    "# Parallel computation of cross validation standard error for different lambdas\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "# Distribute lambdas among processes\n",
    "results = []\n",
    "for i in range(rank, len(lambdas), size):\n",
    "    lambda_ = lambdas[i]\n",
    "    result = calculate_CVSE_for_lambda(lambda_, diff_order, w, y)\n",
    "    results.append(result)\n",
    "\n",
    "# Collect results at root process\n",
    "all_results = comm.gather(results, root=0)\n",
    "\n",
    "# print all results\n",
    "if rank == 0:\n",
    "    final_results = []\n",
    "    for res_list in all_results:\n",
    "        final_results.extend(res_list)\n",
    "    for res in final_results:\n",
    "        print(f\"Lambda: {res[0]}, CV_SE: {res[1]}\")\n",
    "    with open(\"mpi_results.txt\", \"w\") as f: # write to file\n",
    "        for res in final_results:\n",
    "            f.write(f\"{res[0]},{res[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d959f-9011-4fd9-8d5d-0cfb8c7a5c14",
   "metadata": {},
   "source": [
    "# Run the main code for all lambdas in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e085b0b-87c8-46b2-92f1-e56e84ad7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 12 python mpi_GraduationSmoother.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae82bc-bbbd-462d-95cf-5cec5e981ecc",
   "metadata": {},
   "source": [
    "# Plot the CV_SE for different lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba742741-1733-4aa1-b633-5c998dd22f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Read results from the file\n",
    "df = pd.read_csv(\"mpi_results.txt\", names=[\"Lambda\", \"CV_SE\"])\n",
    "\n",
    "# Find the lambda with the minimum CV_SE\n",
    "min_cvse_row = df.loc[df[\"CV_SE\"].idxmin()]\n",
    "min_lambda = min_cvse_row[\"Lambda\"]\n",
    "min_cvse = min_cvse_row[\"CV_SE\"]\n",
    "\n",
    "print(f\"Lambda with minimum CV_SE: {min_lambda}\")\n",
    "print(f\"Minimum CV_SE: {min_cvse}\")\n",
    "\n",
    "# Plot the results\n",
    "fig = px.scatter(df, x=\"Lambda\", y=\"CV_SE\", title=\"CV_SE vs. Lambda\")\n",
    "fig.add_scatter(x=[min_lambda], y=[min_cvse], mode='markers', marker=dict(size=10, color='red'), name='Minimum CV_SE') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67109ca-afd4-4338-b097-79076d379db3",
   "metadata": {},
   "source": [
    "# Smooth the input data with the optimal lambda value obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188ea1c-dd5c-4039-b623-df09837f5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sksparse.cholmod import cholesky\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from scipy.sparse import diags, csr_matrix, csc_matrix\n",
    "from scipy.sparse.linalg import inv\n",
    "import math\n",
    "from scipy.linalg import solve_triangular\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"Graduation\" smoothing technique based on the methodology proposed by: \n",
    "    Eilers, P.H., 2003. A perfect smoother. Analytical chemistry, 75(14), pp.3631-3636. \n",
    "after \n",
    "    Whittaker, E.T., 1922. On a new method of graduation. Proceedings of the Edinburgh Mathematical Society, 41, pp.63-75.\n",
    "\n",
    "\n",
    "INPUTS:\n",
    "    INPUT_xy.csv:                       is the input data file for smoothing purpose. \n",
    "                                        It has two columns with headers, x and y. \n",
    "                                        First column is the x (can be non-uniformly sampled). \n",
    "                                        The second column is the y (to be smoothed).\n",
    "                                        The file is in the same folder as the main code.\n",
    "    \n",
    "    diff_order:                         Differentiation order.\n",
    "    lambdas:                            The coefficient based on the above optimization .\n",
    "\n",
    "\n",
    "OUTPUTS:\n",
    "    Output_xy_uniform_smoothed.csv:     The uniformly sampled smoothed signal, and stored in the csv file.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "file_path = 'INPUT_xy.csv' \n",
    "diff_order = 2\n",
    "lambda_ = min_lambda\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.set_index('X', inplace=True)\n",
    "\n",
    "data['X_Cummulative'] = (data.index - data.index[0])\n",
    "\n",
    "max_seconds = data['X_Cummulative'].max()\n",
    "new_index = pd.RangeIndex(start=data.iloc[0,1], stop=int(max_seconds)+1, step=1)  \n",
    "\n",
    "new_data = pd.DataFrame(index=new_index, columns=['y'])\n",
    "\n",
    "new_data['y'] = 0.0  \n",
    "\n",
    "new_data['weights'] = 0  \n",
    "\n",
    "for tmp_X in new_data.index:\n",
    "    if tmp_X in data['X_Cummulative'].values:\n",
    "        new_data.at[tmp_X, 'y'] = data.loc[data['X_Cummulative'] == tmp_X, 'y'].values[0]\n",
    "        new_data.at[tmp_X, 'weights']=1\n",
    "\n",
    "w = new_data['weights'].to_numpy()\n",
    "y = new_data['y'].to_numpy()\n",
    "x = np.arange(1, len(y) + 1)  \n",
    "\n",
    "m = len(y)\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "data2 = []\n",
    "\n",
    "for i in range(m - diff_order):\n",
    "    for j in range(diff_order + 1):\n",
    "        rows.append(i)\n",
    "        cols.append(i + j)\n",
    "        data2.append((-1)**(diff_order - j) * math.comb(diff_order, j))\n",
    "\n",
    "D = csc_matrix((data2, (rows, cols)), shape=(m - diff_order, m))\n",
    "W = diags(w, 0, format='csc')\n",
    "A = (W + lambda_ * (D.T @ D)) \n",
    "wy = w * y\n",
    "factor = cholesky(A)\n",
    "z=factor(wy)\n",
    "\n",
    "\n",
    "# writing the results\n",
    "Output_xy_uniform_smoothed=pd.DataFrame(data={'y_smoothed':z}, index=x)\n",
    "Output_xy_uniform_smoothed.to_csv('Output_xy_uniform_smoothed.csv')\n",
    "\n",
    "\n",
    "# plotting the results\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data['X_Cummulative'], y=data['y'], name='Raw'))\n",
    "fig.add_trace(go.Scatter(x=x, y=z, name='Smoothed'))\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        title='y'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='X'\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b03433-8b03-4cb9-ad6e-9199ac7b86e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df6213-2b68-446f-8122-5777b4675e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
